{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d09eac65-e4b6-4a31-8d1b-1a6eec8bf9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.6666000000000025\n",
      "Mean Squared Error: 3.528233400000012\n",
      "R-squared: 0.8860036251550865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varad\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 50 features, but RandomForestRegressor is expecting 25 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 155\u001b[0m\n\u001b[0;32m    140\u001b[0m     sf \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch49\u001b[39m\u001b[38;5;124m'\u001b[39m: (simulate_match(df, qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch45\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch45\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], scaler, rf_model), simulate_match(df, qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch46\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch46\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], scaler, rf_model)),\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch50\u001b[39m\u001b[38;5;124m'\u001b[39m: (simulate_match(df, qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch47\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch47\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], scaler, rf_model), simulate_match(df, qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch48\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch48\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], scaler, rf_model)),\n\u001b[0;32m    144\u001b[0m \n\u001b[0;32m    145\u001b[0m     }\n\u001b[0;32m    147\u001b[0m     final \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    148\u001b[0m         \n\u001b[0;32m    149\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch51\u001b[39m\u001b[38;5;124m'\u001b[39m: (simulate_match(df, qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch49\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch49\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], scaler, rf_model), simulate_match(df, qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch50\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], qf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch50\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], scaler, rf_model))\n\u001b[0;32m    150\u001b[0m     \n\u001b[0;32m    151\u001b[0m     }\n\u001b[1;32m--> 155\u001b[0m simulate_match(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeorgia\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m, rf_model)\n",
      "Cell \u001b[1;32mIn[132], line 52\u001b[0m, in \u001b[0;36msimulate_match\u001b[1;34m(df, team1, team2, scaler, rf_model)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate_match\u001b[39m(df, team1, team2, scaler, rf_model):\n\u001b[0;32m     50\u001b[0m     match_stats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m team1]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten(), \n\u001b[0;32m     51\u001b[0m                                   df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m team2]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquad\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()])\n\u001b[1;32m---> 52\u001b[0m     match_outcome \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict([match_stats])\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_outcome \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m team1\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 50 features, but RandomForestRegressor is expecting 25 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Read in csv\n",
    "df = pd.read_csv(r\"C:\\Users\\varad\\Downloads\\euro2024_data (1).csv\")\n",
    "df.fillna(0, inplace=True)\n",
    "df.drop(columns=['played90s_nl2022', 'played90s_wc2022', 'played90s_euro2016', 'played90s_wc2018', 'played90s_euro2021'], inplace=True)\n",
    "\n",
    "# Define feature columns excluding squad\n",
    "feature_columns = df.drop(columns=['squad']).columns\n",
    "\n",
    "# Define target variable\n",
    "target = df['total_90s_played']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feature_columns], target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Import and initialize Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and error testing\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Dictionary containing all the groups for group stage\n",
    "EURO_groups = {\n",
    "    'Group A': ['Germany', 'Scotland', 'Hungary', 'Switzerland'],\n",
    "    'Group B': ['Spain', 'Italy', 'Croatia', 'Albania'],\n",
    "    'Group C': ['Slovenia', 'Denmark', 'Serbia', 'England'],\n",
    "    'Group D': ['Poland', 'Netherlands', 'Austria', 'France'],\n",
    "    'Group E': ['Belgium', 'Slovakia', 'Romania', 'Ukraine'],\n",
    "    'Group F': ['TÃ¼rkiye', 'Portugal', 'Georgia', 'Czech Republic'],\n",
    "}\n",
    "\n",
    "def simulate_match(df, team1, team2, scaler, rf_model):\n",
    "    match_stats = np.concatenate([df[df['squad'] == team1].drop(columns=['squad']).values.flatten(), \n",
    "                                  df[df['squad'] == team2].drop(columns=['squad']).values.flatten()])\n",
    "    match_outcome = rf_model.predict([match_stats])\n",
    "    if match_outcome > 0:\n",
    "        return team1\n",
    "    elif match_outcome < 0:\n",
    "        return team2\n",
    "    else:\n",
    "        return \"Draw\"\n",
    "\n",
    "# Simulates results for a group\n",
    "def simulate_group(df, t1, t2, t3, t4, scaler, rfmodel):\n",
    "    # Initialize new dict to track points\n",
    "    group = {t1: 0, t2: 0, t3: 0, t4: 0}\n",
    "\n",
    "    # Interate to sim matches\n",
    "    for team, i in group:\n",
    "        for opp, j in group:\n",
    "            if (team != opp):\n",
    "                result = simulate_match(df, team, opp, scaler, rf_model)\n",
    "                if result == team:\n",
    "                    group[team] += 3\n",
    "                elif result == opp:\n",
    "                    group[opp] += 3\n",
    "                else:\n",
    "                    group[team] += 1\n",
    "                    group[opp] += 1\n",
    "\n",
    "    # Sort group by points, returns decending list of tuples in the form [(team, points), ...]\n",
    "    group_new = sorted(group.item(), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Returns list of just teams in rank order\n",
    "    teams_ranked = []\n",
    "    for tuple in group_new:\n",
    "        teams_ranked.append(tuple[0])\n",
    "\n",
    "    return teams_ranked\n",
    "\n",
    "def simulate_groupstage():\n",
    "    \n",
    "    groups = EURO_groups\n",
    "    for group in groups:\n",
    "        group_ranked = []\n",
    "        group_ranked = simulate_group(group[1][0], group[1][1], group[1][2], group[1][3])\n",
    "        groups.update({group: group_ranked})\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def knockout_stage(df,groups,scaler,rf_model):\n",
    "    \n",
    "    list39 = ['Group A','Group D','Group E','Group F']\n",
    "    choice39 = random.choice(list39)\n",
    "    \n",
    "    list40 = list39.remove('Group A') #contains D,E,F\n",
    "    if choice39 in list40:\n",
    "        list40.remove(choice39)\n",
    "    choice40 = random.choice(list40)\n",
    "    \n",
    "    list41 = ['Group A','Group B','Group C']\n",
    "    if choice39 in list41:\n",
    "        list41.remove(choice39)\n",
    "    choice41 = random.choice(list41)\n",
    "    \n",
    "    list43 = ['Group A','Group B','Group C','Group D']\n",
    "    if choice39 in list43:\n",
    "        list43.remove(choice39)\n",
    "    if choice40 in list43:\n",
    "        list43.remove(choice40)\n",
    "    if choice41 in list43:\n",
    "        list43.remove(choice41)\n",
    "    choice43 = random.choice(list43)\n",
    "    \n",
    "    r16 = {\n",
    "        'match37': (groups['Group A'][0], groups['Group C'][1]),\n",
    "        'match38': (groups['Group A'][1], groups['Group B'][1]),\n",
    "        'match39': (groups['Group B'][0], groups[choice39][2]),\n",
    "        'match40': (groups['Group C'][0], groups[choice40][2]),\n",
    "        'match41': (groups['Group F'][0], groups[choice41][2]),\n",
    "        'match42': (groups['Group D'][1], groups['Group E'][1]),\n",
    "        'match43': (groups['Group E'][0], groups[choice43][1]),\n",
    "        'match44': (groups['Group D'][0], groups['Group F'][1]),\n",
    "    }\n",
    "    \n",
    "    qf = {\n",
    "        'match45': (simulate_match(df,r16['match39'][0],r16['match39'][1],scaler,rf_model),simulate_match(df,r16['match37'][0],r16_['match37'][1],scaler,rf_model)),\n",
    "        'match46': (simulate_match(df,r16['match41'][0],r16['match41'][1],scaler,rf_model),simulate_match(df,r16['match42'][0],r16['match42'][1],scaler,rf_model)),\n",
    "        'match47': (simulate_match(df,r16['match43'][0],r16['match43'][1],scaler,rf_model),simulate_match(df,r16['match44'][0],r16['match44'][1],scaler,rf_model)),\n",
    "        'match48': (simulate_match(df,r16['match40'][0],r16['match40'][1],scaler,rf_model),simulate_match(df,r16['match38'][0],r16['match38'][1],scaler,rf_model))\n",
    "    }\n",
    "    \n",
    "    sf = {\n",
    "\n",
    "    'match49': (simulate_match(df, qf['match45'][0], qf['match45'][1], scaler, rf_model), simulate_match(df, qf['match46'][0], qf['match46'][1], scaler, rf_model)),\n",
    "    'match50': (simulate_match(df, qf['match47'][0], qf['match47'][1], scaler, rf_model), simulate_match(df, qf['match48'][0], qf['match48'][1], scaler, rf_model)),\n",
    "\n",
    "    }\n",
    "\n",
    "    final = {\n",
    "        \n",
    "    'match51': (simulate_match(df, qf['match49'][0], qf['match49'][1], scaler, rf_model), simulate_match(df, qf['match50'][0], qf['match50'][1], scaler, rf_model))\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "simulate_match(df, 'France', 'Georgia', 0, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c65003-f1a8-4aab-9257-577390f85705",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of feature columns:\", len(feature_columns))\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "\n",
    "print(X_train.shape[1],\n",
    "X_test.shape[1])\n",
    "\n",
    "duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "print(\"Duplicate columns:\", duplicate_columns)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
